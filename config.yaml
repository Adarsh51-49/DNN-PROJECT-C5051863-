# Project Configuration File

project:
  name: "Multimodal Sequence Modeling for Visual Storytelling"
  author: "Your Name"
  version: "1.0.0"
  innovation: "Temporal-Aware Cross-Modal Attention"

data:
  path: "./data/storyreasoning"
  sequence_length: 5
  max_text_length: 100
  image_size: 224
  train_split: 0.7
  val_split: 0.15
  test_split: 0.15
  augment: True
  shuffle: True

model:
  # Architecture parameters
  image_size: 224
  vocab_size: 10000
  embedding_dim: 512
  hidden_dim: 1024
  num_layers: 3
  dropout: 0.3
  attention_dim: 512
  
  # Encoder parameters
  visual_encoder:
    type: "resnet50"
    pretrained: True
    trainable_layers: 4
  
  text_encoder:
    type: "lstm"  # Options: lstm, transformer, gru
    bidirectional: True
    num_heads: 8
  
  # Decoder parameters
  image_decoder:
    type: "conv_transpose"
    channels: [1024, 512, 256, 128, 3]
    kernel_sizes: [4, 4, 4, 4, 4]
    strides: [2, 2, 2, 2, 2]
  
  text_decoder:
    type: "lstm"
    attention: True
    beam_size: 3

training:
  device: "cuda"  # Options: cuda, cpu, mps
  batch_size: 32
  epochs: 50
  learning_rate: 0.001
  weight_decay: 0.0001
  gradient_clip: 1.0
  patience: 10
  min_delta: 0.001
  
  # Learning rate scheduler
  scheduler:
    type: "reduce_on_plateau"
    factor: 0.5
    patience: 5
    min_lr: 1e-6
  
  # Early stopping
  early_stopping:
    enabled: True
    patience: 15
    min_delta: 0.001

innovation:
  # Innovation parameters
  temporal_attention: True
  cross_modal_fusion: True
  attention_heads: 8
  temporal_encoding: "learned"  # Options: learned, sinusoidal, relative
  
  # Multi-task learning
  multi_task:
    enabled: True
    reconstruction_weight: 0.3
    alignment_weight: 0.2
    coherence_weight: 0.5
  
  # Curriculum learning
  curriculum:
    enabled: True
    sequence_lengths: [3, 5, 7]
    epochs_per_length: 10
    final_epochs: 20
  
  learning_rate: 0.0005
  epochs: 50

evaluation:
  metrics:
    - "bleu"
    - "perplexity"
    - "cider"
    - "rouge"
    - "meteor"
    - "repetition_rate"
    - "coherence_score"
  
  human_evaluation:
    num_samples: 100
    scales:
      coherence: 5
      relevance: 5
      creativity: 5
  
  # Generation parameters
  generation:
    max_length: 50
    temperature: 0.8
    top_k: 50
    top_p: 0.95
    repetition_penalty: 1.2

paths:
  data: "./data"
  checkpoints: "./checkpoints"
  results: "./results"
  logs: "./logs"
  
  # Subdirectories
  baseline_results: "./results/baseline"
  improved_results: "./results/improved"
  comparative_analysis: "./results/comparative_analysis"

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "./logs/training.log"
  tensorboard: True
  
  # Progress bar
  progress_bar: True
  update_freq: 10

reproducibility:
  seed: 42
  deterministic: True
  benchmark: False

git:
  repository: "https://github.com/yourusername/project_username"
  branch: "main"
  commit_message: "Initial commit with baseline implementation"